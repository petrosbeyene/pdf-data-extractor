{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4viKtocypSxJ"
      },
      "outputs": [],
      "source": [
        "!pip install openai PyPDF2 nltk textstat pandas pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "from typing import Dict, List, Any, Tuple, Optional\n",
        "from dataclasses import dataclass\n",
        "import datetime\n",
        "from collections import defaultdict\n",
        "\n",
        "import openai\n",
        "import PyPDF2\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import textstat\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "1MaUiByXMYrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class InvestmentInsight:\n",
        "  \"\"\"Data class to store investment insights\"\"\"\n",
        "  category: str\n",
        "  insight: str\n",
        "  confidence: float\n",
        "  supporting_evidence: List[str]\n",
        "  impact_level: str  # High, Medium, Low\n",
        "  timeframe: str  # Short-term, Medium-term, Long-term\n",
        "  source_location: Optional[str] = None  # Page or section reference"
      ],
      "metadata": {
        "id": "19ZUKA6zRaBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PDFInvestmentAnalyzer:\n",
        "  \"\"\"\n",
        "  Comprehensive analyzer for financial documents to extract key investment information\n",
        "  \"\"\"\n",
        "  def __init__(self, openai_api_key: str = None):\n",
        "    \"\"\"\n",
        "    Initialize the analyzer\n",
        "\n",
        "    Args:\n",
        "        openai_api_key: OpenAI API key for enhanced analysis (optional)\n",
        "    \"\"\"\n",
        "    self.openai_api_key = openai_api_key\n",
        "    if openai_api_key:\n",
        "        openai.api_key = openai_api_key\n",
        "\n",
        "    # Initialize NLP tools\n",
        "    self.lemmatizer = WordNetLemmatizer()\n",
        "    self.stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Investment-focused keywords and patterns\n",
        "    self.growth_keywords = [\n",
        "        'growth', 'expansion', 'scaling', 'increasing', 'accelerating',\n",
        "        'growing', 'rise', 'boost', 'enhance', 'improve', 'strengthen',\n",
        "        'momentum', 'trajectory', 'ramp-up', 'scale-up', 'outperform',\n",
        "        'outpacing', 'market share', 'penetration', 'opportunity'\n",
        "    ]\n",
        "\n",
        "    self.financial_keywords = [\n",
        "        'revenue', 'sales', 'turnover', 'ebitda', 'profit', 'margin',\n",
        "        'pat', 'earnings', 'cash flow', 'roi', 'roce', 'roe', 'eps',\n",
        "        'consolidated', 'guidance', 'forecast', 'outlook'\n",
        "    ]\n",
        "\n",
        "    self.risk_keywords = [\n",
        "        'risk', 'challenge', 'concern', 'issue', 'problem', 'headwind',\n",
        "        'pressure', 'decline', 'drop', 'fall', 'weak', 'slow', 'impact',\n",
        "        'disruption', 'uncertainty', 'volatile', 'competition'\n",
        "    ]\n",
        "\n",
        "    self.acquisition_keywords = [\n",
        "        'acquisition', 'merger', 'acquire', 'acquired', 'bought',\n",
        "        'purchase', 'integration', 'synergy', 'consolidation', 'inorganic',\n",
        "        'transformative', 'strategic', 'partnership', 'joint venture'\n",
        "    ]\n",
        "\n",
        "    self.guidance_keywords = [\n",
        "        'guidance', 'target', 'expect', 'forecast', 'outlook',\n",
        "        'projected', 'estimate', 'anticipate', 'confident', 'future',\n",
        "        'next quarter', 'next year', 'long term', 'medium term'\n",
        "    ]\n",
        "\n",
        "    # Numerical pattern for extracting figures\n",
        "    self.number_pattern = r'(\\d+(?:\\.\\d+)?)\\s*(?:crore|million|billion|%|percent)'\n",
        "\n",
        "  # def extract_text_from_pdf(self, pdf_path: str) -> str:\n",
        "  #   \"\"\"\n",
        "  #   Extract text from PDF file\n",
        "\n",
        "  #   Args:\n",
        "  #       pdf_path: Path to PDF file\n",
        "\n",
        "  #   Returns:\n",
        "  #       Extracted text content\n",
        "  #   \"\"\"\n",
        "  #   try:\n",
        "  #       with open(pdf_path, 'rb') as file:\n",
        "  #           pdf_reader = PyPDF2.PdfReader(file)\n",
        "  #           text = \"\"\n",
        "  #           for page in pdf_reader.pages:\n",
        "  #               text += page.extract_text()\n",
        "  #           return text\n",
        "  #   except Exception as e:\n",
        "  #       print(f\"Error extracting PDF: {e}\")\n",
        "  #       return \"\"\n",
        "\n",
        "\n",
        "  def extract_text_from_pdf(self, pdf_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract text from PDF file using pdfplumber for better text quality\n",
        "\n",
        "    Args:\n",
        "        pdf_path: Path to PDF file\n",
        "\n",
        "    Returns:\n",
        "        Extracted text content\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import pdfplumber\n",
        "\n",
        "        text = \"\"\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += page_text + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting PDF with pdfplumber: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "  def preprocess_text(self, text: str) -> str:\n",
        "    \"\"\"\n",
        "    Clean and preprocess the text with improved word separation\n",
        "\n",
        "    Args:\n",
        "        text: Raw text content\n",
        "\n",
        "    Returns:\n",
        "        Preprocessed text\n",
        "    \"\"\"\n",
        "    # Remove contact info, headers, footers\n",
        "    text = re.sub(r'Mumbai.*?\\d{6}', '', text)\n",
        "    text = re.sub(r'Symbol:.*?Code:', '', text)\n",
        "    text = re.sub(r'Membership No\\..*?Encl:', '', text)\n",
        "\n",
        "    # Remove moderator instructions\n",
        "    text = re.sub(r'Ladies and gentlemen.*?JM Financial\\.', '', text)\n",
        "    text = re.sub(r'As a reminder.*?phone\\.', '', text)\n",
        "\n",
        "    # Remove common transcript artifacts\n",
        "    text = re.sub(r'Moderator:', '', text)\n",
        "    text = re.sub(r'Page \\d+', '', text)\n",
        "\n",
        "    # Fix common word concatenation issues\n",
        "    text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', text)  # Insert space before capital letters\n",
        "    text = re.sub(r'(\\d)([A-Za-z])', r'\\1 \\2', text)  # Space between numbers and letters\n",
        "    text = re.sub(r'([A-Za-z])(\\d)', r'\\1 \\2', text)  # Space between letters and numbers\n",
        "    text = re.sub(r'([a-z])(of|to|in|on|at|by|for|with|and|the|a|an)', r'\\1 \\2', text)  # Common word boundaries\n",
        "\n",
        "    # Fix specific financial terms\n",
        "    text = re.sub(r'([a-z])(EBITDA|PAT|ROE|ROCE|YoY|QoQ)', r'\\1 \\2', text)\n",
        "    text = re.sub(r'(EBITDA|PAT|ROE|ROCE|YoY|QoQ)([a-z])', r'\\1 \\2', text)\n",
        "\n",
        "    # Remove extra whitespace and normalize\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'[^\\w\\s\\.\\,\\:\\;\\-\\(\\)\\%\\$]', '', text)\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "  def is_meaningful_sentence(self, sentence: str) -> bool:\n",
        "    \"\"\"\n",
        "    Check if a sentence contains meaningful business content\n",
        "\n",
        "    Args:\n",
        "        sentence: Sentence to evaluate\n",
        "\n",
        "    Returns:\n",
        "        Boolean indicating if sentence is meaningful\n",
        "    \"\"\"\n",
        "    # Skip if mostly contact info, numbers, or formatting\n",
        "    if any(pattern in sentence.lower() for pattern in [\n",
        "        'membership no', 'symbol:', 'mumbai', 'department',\n",
        "        'ladies and gentlemen', 'reminder', 'conference call',\n",
        "        'analyst:', 'management:', 'moderator', 'thank you',\n",
        "        'good day', 'welcome to', 'over to you'\n",
        "    ]):\n",
        "        return False\n",
        "\n",
        "    # Skip very short sentences\n",
        "    if len(sentence.split()) < 8:\n",
        "        return False\n",
        "\n",
        "    # Must contain actual business content\n",
        "    business_indicators = ['revenue', 'growth', 'business', 'market', 'company',\n",
        "                          'acquisition', 'performance', 'margin', 'customer',\n",
        "                          'segment', 'quarter', 'year']\n",
        "    return any(indicator in sentence.lower() for indicator in business_indicators)\n",
        "\n",
        "  def extract_financial_metrics(self, text: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Extract key financial metrics and numbers with context\n",
        "\n",
        "    Args:\n",
        "        text: Preprocessed text\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of financial metrics with context\n",
        "    \"\"\"\n",
        "    metrics = {}\n",
        "\n",
        "    # Revenue patterns with context\n",
        "    revenue_patterns = [\n",
        "        r'(revenue.*?(\\d+(?:\\.\\d+)?)\\s*(?:crore|million|billion).*?)',\n",
        "        r'(sales.*?(\\d+(?:\\.\\d+)?)\\s*(?:crore|million|billion).*?)',\n",
        "        r'(turnover.*?(\\d+(?:\\.\\d+)?)\\s*(?:crore|million|billion).*?)'\n",
        "    ]\n",
        "\n",
        "    # Growth patterns with context\n",
        "    growth_patterns = [\n",
        "        r'(growth.*?(\\d+(?:\\.\\d+)?)\\s*(?:%|percent).*?)',\n",
        "        r'(grew.*?(\\d+(?:\\.\\d+)?)\\s*(?:%|percent).*?)',\n",
        "        r'(increase.*?(\\d+(?:\\.\\d+)?)\\s*(?:%|percent).*?)'\n",
        "    ]\n",
        "\n",
        "    # Margin patterns with context\n",
        "    margin_patterns = [\n",
        "        r'(margin.*?(\\d+(?:\\.\\d+)?)\\s*(?:%|percent).*?)',\n",
        "        r'(ebitda.*?(\\d+(?:\\.\\d+)?)\\s*(?:%|percent).*?)'\n",
        "    ]\n",
        "\n",
        "    # Extract metrics with context\n",
        "    for pattern in revenue_patterns:\n",
        "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "        if matches:\n",
        "            metrics['revenue_context'] = [match[0][:100] for match in matches]  # First 100 chars of context\n",
        "            metrics['revenue_figures'] = [match[1] for match in matches]\n",
        "\n",
        "    for pattern in growth_patterns:\n",
        "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "        if matches:\n",
        "            metrics['growth_context'] = [match[0][:100] for match in matches]\n",
        "            metrics['growth_rates'] = [match[1] for match in matches]\n",
        "\n",
        "    for pattern in margin_patterns:\n",
        "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "        if matches:\n",
        "            metrics['margin_context'] = [match[0][:100] for match in matches]\n",
        "            metrics['margin_figures'] = [match[1] for match in matches]\n",
        "\n",
        "    return metrics\n",
        "\n",
        "  def identify_key_segments(self, text: str) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Identify and extract key segments from the transcript\n",
        "\n",
        "    Args:\n",
        "        text: Preprocessed text\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of key segments\n",
        "    \"\"\"\n",
        "    segments = {}\n",
        "\n",
        "    # Split by common section headers\n",
        "    sections = [\n",
        "        ('opening_remarks', r'opening remarks?|opening comment'),\n",
        "        ('financial_highlights', r'financial performance|financial highlights'),\n",
        "        ('business_update', r'business.*?update|business.*?performance'),\n",
        "        ('outlook', r'outlook|future|guidance|going forward'),\n",
        "        ('qa_section', r'question.*?answer|q&a|questions')\n",
        "    ]\n",
        "\n",
        "    for section_name, pattern in sections:\n",
        "        match = re.search(pattern, text, re.IGNORECASE)\n",
        "        if match:\n",
        "            start = match.start()\n",
        "            # Find next section or end of text\n",
        "            next_sections = [re.search(p, text[start+100:], re.IGNORECASE) for _, p in sections]\n",
        "            next_sections = [m for m in next_sections if m is not None]\n",
        "\n",
        "            if next_sections:\n",
        "                end = min(m.start() for m in next_sections) + start + 100\n",
        "                segments[section_name] = text[start:end]\n",
        "            else:\n",
        "                segments[section_name] = text[start:]\n",
        "\n",
        "    return segments\n",
        "\n",
        "  def extract_growth_drivers(self, text: str) -> List[InvestmentInsight]:\n",
        "    \"\"\"\n",
        "    Extract growth drivers and prospects\n",
        "\n",
        "    Args:\n",
        "        text: Text content\n",
        "\n",
        "    Returns:\n",
        "        List of growth-related insights\n",
        "    \"\"\"\n",
        "    insights = []\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    for sentence in sentences:\n",
        "        # Skip non-meaningful sentences\n",
        "        if not self.is_meaningful_sentence(sentence):\n",
        "            continue\n",
        "\n",
        "        # Check for growth-related content\n",
        "        if any(keyword in sentence.lower() for keyword in self.growth_keywords):\n",
        "            # Extract numerical growth figures\n",
        "            growth_numbers = re.findall(r'(\\d+(?:\\.\\d+)?)\\s*(?:%|percent)', sentence)\n",
        "\n",
        "            # Categorize by impact level\n",
        "            impact_level = \"Medium\"\n",
        "            if growth_numbers:\n",
        "                if any(float(num) > 20 for num in growth_numbers):\n",
        "                    impact_level = \"High\"\n",
        "                elif any(float(num) < 10 for num in growth_numbers):\n",
        "                    impact_level = \"Low\"\n",
        "\n",
        "            # Determine timeframe\n",
        "            timeframe = \"Medium-term\"\n",
        "            if any(term in sentence.lower() for term in ['this year', 'fy24', 'quarter']):\n",
        "                timeframe = \"Short-term\"\n",
        "            elif any(term in sentence.lower() for term in ['long term', 'future', 'next 3']):\n",
        "                timeframe = \"Long-term\"\n",
        "\n",
        "            insight = InvestmentInsight(\n",
        "                category=\"Growth Drivers\",\n",
        "                insight=sentence.strip(),\n",
        "                confidence=0.8,\n",
        "                supporting_evidence=growth_numbers,\n",
        "                impact_level=impact_level,\n",
        "                timeframe=timeframe\n",
        "            )\n",
        "            insights.append(insight)\n",
        "\n",
        "    return insights[:10]  # Return top 10 insights\n",
        "\n",
        "  def extract_business_changes(self, text: str) -> List[InvestmentInsight]:\n",
        "    \"\"\"\n",
        "    Extract key business changes and strategic initiatives\n",
        "\n",
        "    Args:\n",
        "        text: Text content\n",
        "\n",
        "    Returns:\n",
        "        List of business change insights\n",
        "    \"\"\"\n",
        "    insights = []\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    change_indicators = [\n",
        "        'new', 'launch', 'introduce', 'expand', 'acquire', 'partnership',\n",
        "        'strategic', 'initiative', 'transformation', 'restructure'\n",
        "    ]\n",
        "\n",
        "    for sentence in sentences:\n",
        "        # Skip non-meaningful sentences\n",
        "        if not self.is_meaningful_sentence(sentence):\n",
        "            continue\n",
        "\n",
        "        if any(indicator in sentence.lower() for indicator in change_indicators):\n",
        "            # Assess impact based on keywords\n",
        "            impact_level = \"Medium\"\n",
        "            if any(keyword in sentence.lower() for keyword in self.acquisition_keywords):\n",
        "                impact_level = \"High\"\n",
        "            elif 'new customer' in sentence.lower() or 'new product' in sentence.lower():\n",
        "                impact_level = \"High\"\n",
        "\n",
        "            # Determine timeframe based on context\n",
        "            timeframe = \"Medium-term\"\n",
        "            if \"completed\" in sentence.lower() or \"recently\" in sentence.lower():\n",
        "                timeframe = \"Short-term\"\n",
        "            elif \"plan\" in sentence.lower() or \"future\" in sentence.lower():\n",
        "                timeframe = \"Long-term\"\n",
        "\n",
        "            insight = InvestmentInsight(\n",
        "                category=\"Business Changes\",\n",
        "                insight=sentence.strip(),\n",
        "                confidence=0.7,\n",
        "                supporting_evidence=[],\n",
        "                impact_level=impact_level,\n",
        "                timeframe=timeframe\n",
        "            )\n",
        "            insights.append(insight)\n",
        "\n",
        "    return insights[:10]\n",
        "\n",
        "  def extract_financial_guidance(self, text: str) -> List[InvestmentInsight]:\n",
        "    \"\"\"\n",
        "    Extract financial guidance and forward-looking statements\n",
        "\n",
        "    Args:\n",
        "        text: Text content\n",
        "\n",
        "    Returns:\n",
        "        List of guidance insights\n",
        "    \"\"\"\n",
        "    insights = []\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    for sentence in sentences:\n",
        "        # Skip non-meaningful sentences\n",
        "        if not self.is_meaningful_sentence(sentence):\n",
        "            continue\n",
        "\n",
        "        if any(keyword in sentence.lower() for keyword in self.guidance_keywords):\n",
        "            # Extract numerical guidance\n",
        "            numbers = re.findall(self.number_pattern, sentence)\n",
        "\n",
        "            # Determine timeframe based on context\n",
        "            timeframe = \"Short-term\"\n",
        "            if any(term in sentence.lower() for term in ['long term', 'future', 'years']):\n",
        "                timeframe = \"Long-term\"\n",
        "            elif any(term in sentence.lower() for term in ['medium term', 'next year']):\n",
        "                timeframe = \"Medium-term\"\n",
        "\n",
        "            insight = InvestmentInsight(\n",
        "                category=\"Financial Guidance\",\n",
        "                insight=sentence.strip(),\n",
        "                confidence=0.9,\n",
        "                supporting_evidence=numbers,\n",
        "                impact_level=\"High\",\n",
        "                timeframe=timeframe\n",
        "            )\n",
        "            insights.append(insight)\n",
        "\n",
        "    return insights[:5]\n",
        "\n",
        "  def extract_risks_and_challenges(self, text: str) -> List[InvestmentInsight]:\n",
        "    \"\"\"\n",
        "    Extract risks and challenges mentioned\n",
        "\n",
        "    Args:\n",
        "        text: Text content\n",
        "\n",
        "    Returns:\n",
        "        List of risk insights\n",
        "    \"\"\"\n",
        "    insights = []\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    for sentence in sentences:\n",
        "        # Skip non-meaningful sentences\n",
        "        if not self.is_meaningful_sentence(sentence):\n",
        "            continue\n",
        "\n",
        "        if any(keyword in sentence.lower() for keyword in self.risk_keywords):\n",
        "            # Determine impact level based on language intensity\n",
        "            impact_level = \"Medium\"\n",
        "            high_intensity = ['significant', 'major', 'substantial', 'critical', 'severe']\n",
        "            if any(word in sentence.lower() for word in high_intensity):\n",
        "                impact_level = \"High\"\n",
        "\n",
        "            insight = InvestmentInsight(\n",
        "                category=\"Risks & Challenges\",\n",
        "                insight=sentence.strip(),\n",
        "                confidence=0.6,\n",
        "                supporting_evidence=[],\n",
        "                impact_level=impact_level,\n",
        "                timeframe=\"Short-term\"\n",
        "            )\n",
        "            insights.append(insight)\n",
        "\n",
        "    return insights[:5]\n",
        "\n",
        "  def analyze_acquisition_impact(self, text: str, acquisition_name: str = None) -> Dict[str, List[str]]:\n",
        "    \"\"\"\n",
        "    Analyze the impact of a specific acquisition\n",
        "\n",
        "    Args:\n",
        "        text: Text content\n",
        "        acquisition_name: Name of the acquisition to focus on (optional)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with acquisition analysis\n",
        "    \"\"\"\n",
        "    acquisition_info = {\n",
        "        'acquisition_details': [],\n",
        "        'financial_impact': [],\n",
        "        'strategic_benefits': [],\n",
        "        'integration_plan': []\n",
        "    }\n",
        "\n",
        "    if not acquisition_name:\n",
        "        # Improved acquisition name detection\n",
        "        acquisition_patterns = [\n",
        "            r'(acquisition of|acquired|bought)\\s+([A-Z][A-Za-z\\s]+(?:India|Limited|Corp|Inc|Pack)?)',\n",
        "            r'(transformative acquisition of)\\s+([A-Z][A-Za-z\\s]+)',\n",
        "            r'(acquiring)\\s+([A-Z][A-Za-z\\s]+(?:India|Limited|Corp|Inc|Pack)?)'\n",
        "        ]\n",
        "\n",
        "        for pattern in acquisition_patterns:\n",
        "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "            if matches:\n",
        "                acquisition_name = matches[0][1].strip()\n",
        "                break\n",
        "\n",
        "    if not acquisition_name:\n",
        "        return acquisition_info\n",
        "\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    for sentence in sentences:\n",
        "        if acquisition_name.lower() in sentence.lower() and self.is_meaningful_sentence(sentence):\n",
        "            sentence_lower = sentence.lower()\n",
        "\n",
        "            if any(keyword in sentence_lower for keyword in ['acquired', 'acquisition', 'bought']):\n",
        "                acquisition_info['acquisition_details'].append(sentence.strip())\n",
        "\n",
        "            elif any(keyword in sentence_lower for keyword in ['revenue', 'sales', 'margin', 'growth']):\n",
        "                acquisition_info['financial_impact'].append(sentence.strip())\n",
        "\n",
        "            elif any(keyword in sentence_lower for keyword in ['synergy', 'customer', 'technology', 'capability']):\n",
        "                acquisition_info['strategic_benefits'].append(sentence.strip())\n",
        "\n",
        "            elif any(keyword in sentence_lower for keyword in ['integration', 'plan', 'consolidate']):\n",
        "                acquisition_info['integration_plan'].append(sentence.strip())\n",
        "\n",
        "    return acquisition_info\n",
        "\n",
        "  def generate_summary_with_gpt(self, text: str) -> str:\n",
        "    \"\"\"\n",
        "    Generate executive summary using GPT (if API key provided)\n",
        "\n",
        "    Args:\n",
        "        text: Full text content\n",
        "\n",
        "    Returns:\n",
        "        Executive summary\n",
        "    \"\"\"\n",
        "    if not self.openai_api_key:\n",
        "        return \"GPT summary not available - no API key provided\"\n",
        "\n",
        "    try:\n",
        "        from openai import OpenAI\n",
        "        client = OpenAI(api_key=self.openai_api_key)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        Analyze this earnings call transcript and provide a concise executive summary\n",
        "        focusing on key investment highlights:\n",
        "\n",
        "        1. Major financial performance metrics\n",
        "        2. Key business developments and changes\n",
        "        3. Growth drivers and opportunities\n",
        "        4. Forward guidance and outlook\n",
        "        5. Key risks or challenges mentioned\n",
        "\n",
        "        Transcript: {text[:4000]}...\n",
        "\n",
        "        Provide a structured summary in 300-400 words that would be valuable for an investor.\n",
        "        Focus on material information that could affect future earnings and growth.\n",
        "        \"\"\"\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a financial analyst expert at summarizing earnings calls for investors.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=500,\n",
        "            temperature=0.3\n",
        "        )\n",
        "\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error generating GPT summary: {e}\"\n",
        "\n",
        "  def analyze_document(self, text_content: str, company_name: str = None) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Main analysis function that extracts all key investment information\n",
        "\n",
        "    Args:\n",
        "        text_content: Full text content of earnings call or financial report\n",
        "        company_name: Name of the company (optional)\n",
        "\n",
        "    Returns:\n",
        "        Comprehensive analysis results\n",
        "    \"\"\"\n",
        "    # Preprocess text\n",
        "    clean_text = self.preprocess_text(text_content)\n",
        "\n",
        "    # Extract different types of insights\n",
        "    growth_insights = self.extract_growth_drivers(clean_text)\n",
        "    business_changes = self.extract_business_changes(clean_text)\n",
        "    financial_guidance = self.extract_financial_guidance(clean_text)\n",
        "    risks = self.extract_risks_and_challenges(clean_text)\n",
        "\n",
        "    # Extract financial metrics\n",
        "    financial_metrics = self.extract_financial_metrics(clean_text)\n",
        "\n",
        "    # Identify key segments\n",
        "    segments = self.identify_key_segments(clean_text)\n",
        "\n",
        "    # Analyze acquisitions\n",
        "    acquisition_analysis = self.analyze_acquisition_impact(clean_text)\n",
        "\n",
        "    # Generate summary\n",
        "    executive_summary = self.generate_summary_with_gpt(clean_text)\n",
        "\n",
        "    # Compile results\n",
        "    results = {\n",
        "        'company_name': company_name,\n",
        "        'executive_summary': executive_summary,\n",
        "        'financial_metrics': financial_metrics,\n",
        "        'growth_insights': [insight.__dict__ for insight in growth_insights],\n",
        "        'business_changes': [insight.__dict__ for insight in business_changes],\n",
        "        'financial_guidance': [insight.__dict__ for insight in financial_guidance],\n",
        "        'risks_challenges': [insight.__dict__ for insight in risks],\n",
        "        'acquisition_analysis': acquisition_analysis,\n",
        "        'key_segments': segments,\n",
        "        'analysis_metadata': {\n",
        "            'total_insights': len(growth_insights + business_changes + financial_guidance + risks),\n",
        "            'text_length': len(clean_text),\n",
        "            'readability_score': textstat.flesch_reading_ease(clean_text),\n",
        "            'analysis_date': datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "  def generate_investment_report(self, analysis_results: Dict[str, Any]) -> str:\n",
        "    \"\"\"\n",
        "    Generate a formatted investment analysis report\n",
        "\n",
        "    Args:\n",
        "        analysis_results: Results from analyze_document\n",
        "\n",
        "    Returns:\n",
        "        Formatted report string\n",
        "    \"\"\"\n",
        "    report = []\n",
        "    company_name = analysis_results.get('company_name', 'Company')\n",
        "    report.append(\"=\" * 80)\n",
        "    report.append(f\"{company_name.upper()} - INVESTMENT ANALYSIS REPORT\")\n",
        "    report.append(\"=\" * 80)\n",
        "\n",
        "    # Executive Summary\n",
        "    report.append(\"\\n📊 EXECUTIVE SUMMARY\")\n",
        "    report.append(\"-\" * 50)\n",
        "    report.append(analysis_results['executive_summary'])\n",
        "\n",
        "    # Financial Metrics\n",
        "    report.append(\"\\n💰 KEY FINANCIAL METRICS\")\n",
        "    report.append(\"-\" * 50)\n",
        "    for metric, values in analysis_results['financial_metrics'].items():\n",
        "        if values:\n",
        "            report.append(f\"{metric.replace('_', ' ').title()}: {', '.join(values)}\")\n",
        "\n",
        "    # Acquisition Analysis\n",
        "    if any(analysis_results['acquisition_analysis'].values()):\n",
        "        report.append(\"\\n🔄 ACQUISITION ANALYSIS\")\n",
        "        report.append(\"-\" * 50)\n",
        "        for category, items in analysis_results['acquisition_analysis'].items():\n",
        "            if items:\n",
        "                report.append(f\"\\n{category.replace('_', ' ').title()}:\")\n",
        "                for item in items[:3]:\n",
        "                    report.append(f\"• {item}\")\n",
        "\n",
        "    # Growth Insights\n",
        "    report.append(\"\\n🚀 GROWTH DRIVERS & PROSPECTS\")\n",
        "    report.append(\"-\" * 50)\n",
        "    for insight in analysis_results['growth_insights']:\n",
        "        report.append(f\"• {insight['insight']}\")\n",
        "        if insight['supporting_evidence']:\n",
        "            report.append(f\"  Evidence: {', '.join(insight['supporting_evidence'])}\")\n",
        "        report.append(f\"  Impact: {insight['impact_level']} | Timeframe: {insight['timeframe']}\")\n",
        "        report.append(\"\")\n",
        "\n",
        "    # Business Changes\n",
        "    report.append(\"\\n🔄 KEY BUSINESS CHANGES\")\n",
        "    report.append(\"-\" * 50)\n",
        "    for insight in analysis_results['business_changes']:\n",
        "        report.append(f\"• {insight['insight']}\")\n",
        "        report.append(f\"  Impact: {insight['impact_level']} | Timeframe: {insight['timeframe']}\")\n",
        "        report.append(\"\")\n",
        "\n",
        "    # Financial Guidance\n",
        "    report.append(\"\\n🎯 FINANCIAL GUIDANCE & OUTLOOK\")\n",
        "    report.append(\"-\" * 50)\n",
        "    for insight in analysis_results['financial_guidance']:\n",
        "        report.append(f\"• {insight['insight']}\")\n",
        "        if insight['supporting_evidence']:\n",
        "            report.append(f\"  Numbers: {', '.join(insight['supporting_evidence'])}\")\n",
        "        report.append(f\"  Timeframe: {insight['timeframe']}\")\n",
        "        report.append(\"\")\n",
        "\n",
        "    # Risks & Challenges\n",
        "    report.append(\"\\n⚠️ RISKS & CHALLENGES\")\n",
        "    report.append(\"-\" * 50)\n",
        "    for insight in analysis_results['risks_challenges']:\n",
        "        report.append(f\"• {insight['insight']}\")\n",
        "        report.append(f\"  Impact: {insight['impact_level']}\")\n",
        "        report.append(\"\")\n",
        "\n",
        "    # Investment Thesis\n",
        "    report.append(\"\\n💡 INVESTMENT THESIS\")\n",
        "    report.append(\"-\" * 50)\n",
        "    # Generate investment thesis points based on the analysis\n",
        "    thesis_points = []\n",
        "\n",
        "    # Add growth-related thesis points\n",
        "    if analysis_results['growth_insights']:\n",
        "        high_impact_growth = [i for i in analysis_results['growth_insights'] if i['impact_level'] == 'High']\n",
        "        if high_impact_growth:\n",
        "            thesis_points.append(f\"Strong growth potential identified in key areas\")\n",
        "\n",
        "    # Add acquisition-related thesis points\n",
        "    if analysis_results['acquisition_analysis']['strategic_benefits']:\n",
        "        thesis_points.append(f\"Strategic acquisitions enhancing capabilities and market position\")\n",
        "\n",
        "    # Add guidance-related thesis points\n",
        "    if analysis_results['financial_guidance']:\n",
        "        thesis_points.append(f\"Management provides positive forward guidance\")\n",
        "\n",
        "    # Add risk-related thesis points\n",
        "    if analysis_results['risks_challenges']:\n",
        "        thesis_points.append(f\"Key risks to monitor include: {analysis_results['risks_challenges'][0]['insight'][:50]}...\")\n",
        "\n",
        "    for point in thesis_points:\n",
        "        report.append(f\"✓ {point}\")\n",
        "\n",
        "    # Metadata\n",
        "    report.append(\"\\n📈 ANALYSIS METADATA\")\n",
        "    report.append(\"-\" * 50)\n",
        "    metadata = analysis_results['analysis_metadata']\n",
        "    report.append(f\"Total Insights Extracted: {metadata['total_insights']}\")\n",
        "    report.append(f\"Document Length: {metadata['text_length']} characters\")\n",
        "    report.append(f\"Readability Score: {metadata['readability_score']:.1f}\")\n",
        "    report.append(f\"Analysis Date: {metadata['analysis_date']}\")\n",
        "\n",
        "    return \"\\n\".join(report)\n"
      ],
      "metadata": {
        "id": "yHWSACYkMfae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set your OpenAI API key (optional)\n",
        "# import os\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
        "# api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Initialize the analyzer\n",
        "analyzer = PDFInvestmentAnalyzer()  # or PDFInvestmentAnalyzer(openai_api_key=api_key)\n",
        "\n",
        "# Set path to your PDF in Google Drive\n",
        "# IMPORTANT: Upload your PDF to Google Drive PDFs folder first, then use the path\n",
        "pdf_path = \"/content/drive/MyDrive/PDFs/SJS_Transcript_Call.pdf\""
      ],
      "metadata": {
        "id": "VfCCoPLdMyRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract text from PDF\n",
        "text_content = analyzer.extract_text_from_pdf(pdf_path)\n",
        "\n",
        "# Check if text extraction was successful\n",
        "if not text_content:\n",
        "    print(\"Error: Could not extract text from PDF. Check the file path.\")\n",
        "else:\n",
        "    print(f\"Successfully extracted {len(text_content)} characters of text.\")\n",
        "\n",
        "    # Analyze the document\n",
        "    company_name = \"SJS Enterprises\"\n",
        "    results = analyzer.analyze_document(text_content, company_name=company_name)\n",
        "\n",
        "    # Generate and display report\n",
        "    report = analyzer.generate_investment_report(results)\n",
        "    print(report)\n",
        "\n",
        "    # Save results to JSON\n",
        "    with open('/content/investment_analysis.json', 'w') as f:\n",
        "        json.dump(results, f, indent=2, default=str)\n",
        "\n",
        "    print(\"\\nAnalysis complete! Results saved to 'investment_analysis.json'\")\n",
        "\n",
        "    # Create visualization of insights\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    metrics_df = pd.DataFrame({\n",
        "        'Category': ['Growth', 'Financial', 'Risk', 'Strategic'],\n",
        "        'Insights Count': [\n",
        "            len(results['growth_insights']),\n",
        "            len(results['financial_guidance']),\n",
        "            len(results['risks_challenges']),\n",
        "            len(results['business_changes'])\n",
        "        ]\n",
        "    })\n",
        "\n",
        "    # Plot insights distribution\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(metrics_df['Category'], metrics_df['Insights Count'], color=['green', 'blue', 'red', 'orange'])\n",
        "    plt.title('Investment Insights Distribution')\n",
        "    plt.xlabel('Category')\n",
        "    plt.ylabel('Count')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "8G_EQR6ONQjB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}